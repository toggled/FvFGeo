{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x307LLtHZczD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch_geometric.nn as nng\n",
    "import torch\n",
    "import random\n",
    "#from torch_geometric.utils import add_self_loops #ADDED!\n",
    "import torch.nn.functional as F #ADDED\n",
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "# from torch.nn import LSTM\n",
    "# from torch_sparse import SparseTensor, matmul\n",
    "# from torch_geometric.nn.aggr import Aggregation, MultiAggregation\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import Adj, OptPairTensor, Size\n",
    "import torchvision.ops\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader, DataListLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "iN10RHM9vyKF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the network as described in (https://github.com/cfl-minds/gnn_laminar_flow)\n",
    "# but using pyTorch\n",
    "\n",
    "###############################\n",
    "### EdgeSmoothing CLASS DEF ###\n",
    "###############################\n",
    "#@title EdgeSmoothing layer codes\n",
    "class EdgeSmoothing(nng.conv.MessagePassing): #EdgeSmoothing(nng.conv.GCNConv):\n",
    "    '''Convolutions class as described in paper, built on GCNConv, \n",
    "    with SGCN and FVnew adaptations'''\n",
    "    def __init__(self,**kwargs):\n",
    "        kwargs.setdefault('aggr', 'mean')\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    #def forward(self, x: Tensor, edge_index: Adj, edge_weight: OptTensor = None) -> Tensor:\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        # propagate_type: (x: Tensor, edge_weight: OptTensor)\n",
    "        #out = self.propagate(edge_index, x=x, edge_weight=edge_weight, size=None)\n",
    "        out = self.propagate(edge_index=edge_index, x=x) #for FVnew\n",
    "\n",
    "        return out\n",
    "\n",
    "    #def message(self, x_j: Tensor, edge_weight: OptTensor) -> Tensor:\n",
    "    #   return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
    "    def message(self, x_j, x_i, edge_feat=None, edge_attr=None):\n",
    "        \"\"\"\n",
    "        x_j [num_edges, label_dim]\n",
    "        x_i [num_edges, label_dim]\n",
    "        \"\"\"\n",
    "        symmetric = (x_j + x_i)/2 #paper: symmetric node features\n",
    "        return symmetric\n",
    "\n",
    "    #def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "    #    return spmm(adj_t, x, reduce=self.aggr)\n",
    "\n",
    "    def update(self, aggr_out, x_j):\n",
    "        \"\"\"\n",
    "        aggr_out [num_nodes, label_dim, out_channels]\n",
    "        \"\"\"\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**Models 1 and 2**\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "V2hY7STEqV4N",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the network as described in (https://github.com/cfl-minds/gnn_laminar_flow)\n",
    "# but using pyTorch\n",
    "\n",
    "class swish(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "#################################\n",
    "## InvariantEdgeConv CLASS DEF ##\n",
    "#################################\n",
    "#@title InvariantEdgeConv codes, with node_attr_num and edge_attr_num\n",
    "class InvariantEdgeConv(nng.conv.MessagePassing): #InvariantEdgeConv(nng.conv.GCNConv):\n",
    "    '''Convolutions class as described in paper, built on GCNConv, \n",
    "    with SGCN and FVnew adaptations'''\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        #aggr: Optional[Union[str, List[str], Aggregation]] = 'add',\n",
    "\n",
    "        old_mlp_ief: int = 0, #paper: previous edge feature dimension\n",
    "        mlp_hs: int = 128, #paper: two MLPs with hidden size 128 used\n",
    "        mlp_ief: int = 1, #paper: one MLP with intermediate edge feature dimension fe\n",
    "        \n",
    "        node_attr_num: int = 0, #FVnew: number of persistent node_attr\n",
    "        edge_attr_num: int = 0, #FVnew: number of edge_attr + rel_node_attr\n",
    "        hidden_size: int = 0, #sGCN: convolution internal hidden size\n",
    "        dropout: float = 0, #sGCN: dropout\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels + node_attr_num\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        #paper####\n",
    "        # self.mlp_message = nng.MLP([in_channels*2+old_mlp_ief, mlp_hs, mlp_ief],act='swish', bias=True)\n",
    "        # self.mlp_update = nng.MLP([mlp_ief+in_channels, mlp_hs, out_channels],act='swish', bias=True)\n",
    "        self.mlp_message = torchvision.ops.MLP(in_channels*2+old_mlp_ief, [mlp_hs, mlp_ief], \\\n",
    "                                               activation_layer=swish, bias=True)\n",
    "        self.mlp_update = torchvision.ops.MLP(mlp_ief+in_channels, [mlp_hs, out_channels], \\\n",
    "                                              activation_layer=swish, bias=True)\n",
    "        # self.mlp_message = torchvision.ops.MLP(in_channels*2+old_mlp_ief, [mlp_hs, mlp_ief], \\\n",
    "        #                                        activation_layer=None, bias=True)\n",
    "        # self.mlp_update = torchvision.ops.MLP(mlp_ief+in_channels, [mlp_hs, out_channels], \\\n",
    "        #                                       activation_layer=None, bias=True)\n",
    "        self.new_edge_features = None #torch.tensor([0.])\n",
    "\n",
    "        #FVnew or sGCN####\n",
    "        # self.lin_in = torch.nn.Linear(edge_attr_num, hidden_size * in_channels)\n",
    "        # self.lin_out = torch.nn.Linear(hidden_size * in_channels, out_channels)\n",
    "        # self.dropout = dropout ####\n",
    "\n",
    "    #def forward(self, x: Tensor, edge_index: Adj, edge_weight: OptTensor = None) -> Tensor:\n",
    "    def forward(self, x, edge_index, edge_feat=None, edge_attr=None, node_attr=None):\n",
    "\n",
    "        if (node_attr is not None): #for FVnew\n",
    "            x = torch.cat((x,node_attr),dim=1) #persistent node_attr.\n",
    "\n",
    "        # if edge_feat is None: #for paper: previous edge feat added if existent\n",
    "        #     edge_feat = torch.zeros((edge_index.size(1),1))\n",
    "        out = self.propagate(x=x, edge_index=edge_index, edge_feat=edge_feat, edge_attr=edge_attr) #for FVnew\n",
    "\n",
    "        return out, self.new_edge_features\n",
    "\n",
    "    #def message(self, x_j: Tensor, edge_weight: OptTensor) -> Tensor:\n",
    "    #   return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
    "    def message(self, x_j, x_i, edge_feat, edge_attr=None):\n",
    "        \"\"\"\n",
    "        x_j [num_edges, label_dim]\n",
    "        x_i [num_edges, label_dim]\n",
    "        edge_attr [num_edges, #attr] or none ##ADDED\n",
    "        \"\"\"\n",
    "        symmetric = (x_j + x_i)/2 #paper: symmetric node features\n",
    "        asymmetric = abs(x_j - x_i)/2 #instead of raw features x_j and x_i\n",
    "        if edge_feat is not None:\n",
    "            new_edge_feat = torch.cat((symmetric,asymmetric,edge_feat),dim=1)\n",
    "        else:\n",
    "            new_edge_feat = torch.cat((symmetric,asymmetric),dim=1)\n",
    "        message = self.mlp_message(new_edge_feat)\n",
    "        # message = message * F.sigmoid(message) #MLP swish activation if act was None\n",
    "        self.new_edge_features = message\n",
    "\n",
    "        ##for FVnew ####\n",
    "        # if edge_attr is not None: \n",
    "        #   scaling = F.relu(self.lin_in(edge_attr))  # [n_edges, hidden_size * in_channels]\n",
    "        # else:\n",
    "        #   scaling = torch.ones(x_j.size()).unsqueeze(-1).to(x_j.device)\n",
    "        # n_edges = x_j.size(0)\n",
    "        # # [n_edges, in_channels, ...] * [n_edges, in_channels, 1]\n",
    "        # result = scaling.reshape(n_edges, self.in_channels, -1) * message.unsqueeze(-1)\n",
    "        ####\n",
    "\n",
    "        return message #result.view(n_edges, -1)\n",
    "\n",
    "    #def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "    #    return spmm(adj_t, x, reduce=self.aggr)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        \"\"\"\n",
    "        x_j [num_nodes, label_dim, 1]\n",
    "        aggr_out [num_nodes, label_dim, out_channels]\n",
    "        \"\"\"\n",
    "        aggr_out = torch.cat((x,aggr_out),dim=1) #paper\n",
    "        aggr_out = self.mlp_update(aggr_out)\n",
    "        # aggr_out = aggr_out * F.sigmoid(aggr_out) #MLP swish activation if act was None\n",
    "\n",
    "        ##for sGCN ####\n",
    "        # aggr_out = self.lin_out(aggr_out)  #[num_nodes, label_dim, out_features]\n",
    "        # aggr_out = torch.tanh(aggr_out); #aggr_out = F.relu(aggr_out)\n",
    "        # aggr_out = F.dropout(aggr_out, p=self.dropout, training=self.training)\n",
    "        ####\n",
    "\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "J0VnuW3bvgTl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "## InvariantEdgeModel CLASS DEF ##\n",
    "##################################\n",
    "#@title InvariantEdgeModel codes\n",
    "#https://github.com/cfl-minds/gnn_laminar_flow/blob/main/network_utils.py#L22\n",
    "class InvariantEdgeModel(nn.Module):\n",
    "    def __init__(self, input_size=3, input_edge_feat=3, edge_feature_dim=[4,8,16,32,64,64,32,16], \\\n",
    "                 num_filters=[8,16,32,64,64,32,16,8], output_size=3, \\\n",
    "                 node_attr_num=0, edge_attr_num=0, FV_hidden_size=0):\n",
    "        super().__init__()\n",
    "\n",
    "        num_filters = [input_size-2] + num_filters\n",
    "        edge_feature_dim = [input_edge_feat] + edge_feature_dim\n",
    "        #increase layer input channel size by 2 because of skip links\n",
    "        self.layers = [InvariantEdgeConv(in_channels = num_filters[i]+2, \n",
    "                                         out_channels = num_filters[i+1],\n",
    "                                         old_mlp_ief = edge_feature_dim[i],\n",
    "                                         mlp_hs = 128,\n",
    "                                         mlp_ief = edge_feature_dim[i+1],\n",
    "                                         node_attr_num = node_attr_num,\n",
    "                                         edge_attr_num = edge_attr_num,\n",
    "                                         hidden_size = FV_hidden_size, \n",
    "                                         dropout = 0) \\\n",
    "                       for i in range(len(num_filters)-1)]\n",
    "        self.layers = torch.nn.ModuleList(self.layers)\n",
    "\n",
    "        self.smooth_layer = EdgeSmoothing()\n",
    "        self.final_layer = Linear(num_filters[-1]+2, output_size, bias=True)\n",
    "\n",
    "    def forward(self, data): #just data input for DataParallel from listloader\n",
    "        x = data.x.clone()\n",
    "        x_0 = data.x.clone()[:,0:2] #the coordinate data for skip links\n",
    "        edge_feat = x[data.edge_index,:].mean(0) #size Ex3 or Ex12\n",
    "        #edge_feat = None #if no initial edge features\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x,edge_feat = layer(x, data.edge_index, edge_feat=edge_feat, edge_attr=None, node_attr=None)\n",
    "            x = self.smooth_layer(x, data.edge_index)\n",
    "            x = torch.cat((x_0,x),dim=1) #skip links\n",
    "\n",
    "        x = self.final_layer(x)\n",
    "\n",
    "        return x, data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "id": "UqK5tH2KCGCt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define training function\n",
    "# https://github.com/cfl-minds/gnn_laminar_flow/blob/main/training.py\n",
    "# https://github.com/cfl-minds/gnn_laminar_flow/blob/main/training_utils.py\n",
    "\n",
    "##############################\n",
    "### IVEModelfit CLASS DEF ####\n",
    "##############################\n",
    "#@title IVEModelfit CLASS: fit() func\n",
    "class IVEModelfit:\n",
    "    def __init__(self, input_size=3, input_edge_feat=0, edge_feature_dim=[4,8,16,32,64,64,32,16], \\\n",
    "                 num_filters=[8,16,32,64,64,32,16,8], output_size=3, \\\n",
    "                 node_attr_num=0, edge_attr_num=0, FV_hidden_size=0, dropout=0, device='cuda:0'):\n",
    "        self.model = InvariantEdgeModel(input_size = input_size,\n",
    "                                        input_edge_feat = input_edge_feat,\n",
    "                                        edge_feature_dim=edge_feature_dim,\n",
    "                                        num_filters=num_filters,\n",
    "                                        output_size = output_size,\n",
    "                                        node_attr_num=0, edge_attr_num=0, FV_hidden_size=0)\n",
    "        # if torch.cuda.device_count() > 1:\n",
    "        #     self.model = nn.DataParallel(self.model)\n",
    "        self.model.to(device); self.device=device; self.mean,self.var = None,None\n",
    "        self.tb = SummaryWriter() #tensorboard --logdir=runs\n",
    "\n",
    "    def fit(self, path, dataset, valset, max_epoch=1000, bs=64, lr=0.002, weight_decay=0.002, verbose=True):\n",
    "        criterion = nn.L1Loss().to(self.device);\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=0)\n",
    "        lambda1 = lambda epoch: 1/(1+epoch*weight_decay) #decay rate is weight decay\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda1) #lr is lr0*lambda1\n",
    "        \n",
    "        self.model.train() #force dropouts to occur.\n",
    "        start=time.time(); #print(self.model);\n",
    "        self.tb = SummaryWriter() #TensorBoard to show progress\n",
    "        scaler = torch.cuda.amp.GradScaler() #ADDED: half pres\n",
    "\n",
    "        #for epoch in range(max_epoch):\n",
    "        epoch = 0; early_stop = 0; min_val_loss = torch.inf\n",
    "        while epoch < max_epoch:\n",
    "            running_loss=0; num_batches=0\n",
    "            # create minibatches\n",
    "            trainLoader = DataLoader(dataset, batch_size=bs, shuffle=True)\n",
    "            #trainLoader = DataListLoader(dataset, batch_size=bs, shuffle=True)\n",
    "\n",
    "            for batch_list in trainLoader:\n",
    "              #batch = batch.to(self.device)\n",
    "              optimizer.zero_grad() #ADDED\n",
    "\n",
    "              # do one step of stochastic gradient descent: U=U-lr(dL/dU)\n",
    "              with torch.cuda.amp.autocast(): #ADDED: half pres\n",
    "                  batch_list = batch_list.to(self.device)\n",
    "                  outputs, GTy = self.model(batch_list)\n",
    "                  loss = criterion(outputs, GTy)\n",
    "\n",
    "              scaler.scale(loss).backward() #ADDED: half pres\n",
    "              nn.utils.clip_grad_norm_(self.model.parameters(), 5) #if nan loss!\n",
    "              scaler.step(optimizer) #ADDED: half pres\n",
    "              scaler.update() #ADDED: half pres\n",
    "\n",
    "              # add the loss of this batch to the running loss\n",
    "              running_loss += loss.detach().item(); num_batches+=1\n",
    "\n",
    "            # compute stats for the full training set\n",
    "            scheduler.step() #anneal lr\n",
    "            total_loss = running_loss/num_batches; elapsed = time.time()-start\n",
    "            self.tb.add_scalar(\"Loss/Epoch\", total_loss, epoch) #TB plot loss\n",
    "\n",
    "            if verbose & (epoch%5 == 0):\n",
    "                #print('Epoch {} loss: {}'.format(epoch+1, loss.item()))\n",
    "                print('epoch=',epoch,'\\t time=',elapsed,'\\t loss=',total_loss)\n",
    "            \n",
    "\n",
    "            # check stats for validation set, for early stopping\n",
    "            running_loss=0; num_batches=0; \n",
    "            valLoader = DataLoader(valset, batch_size=bs, shuffle=True)\n",
    "            #valLoader = DataListLoader(valset, batch_size=bs, shuffle=True)\n",
    "            for batch_list in valLoader:\n",
    "                with torch.cuda.amp.autocast(): #ADDED: half pres\n",
    "                    batch_list = batch_list.to(self.device)\n",
    "                    outputs, GTy = self.model(batch_list)\n",
    "                    loss = criterion(outputs, GTy)\n",
    "                running_loss += loss.detach().item(); num_batches+=1\n",
    "            val_loss = running_loss/num_batches\n",
    "            self.tb.add_scalar(\"ValLoss/Epoch\", val_loss, epoch) #TB plot loss\n",
    "            # if not improved in 60 epochs, end training.\n",
    "            if val_loss < min_val_loss:\n",
    "                early_stop = 0; min_val_loss = val_loss\n",
    "                with open(path+'IVEModel_checkpoint_'+str(epoch)+'.txt', 'wb') as f:\n",
    "                    torch.save(self.model, f) #save model checkpoint\n",
    "            else:\n",
    "                early_stop += 1\n",
    "            epoch = max_epoch+1 if early_stop>=60 else epoch+1\n",
    "\n",
    "        self.tb.close #Tensorboard close\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 \t time= 6.149606704711914 \t loss= 0.13185713574290275\n",
      "epoch= 5 \t time= 39.047693490982056 \t loss= 0.06717705965042114\n",
      "epoch= 10 \t time= 71.73647475242615 \t loss= 0.048442137092351914\n",
      "epoch= 15 \t time= 104.58683347702026 \t loss= 0.04115691296756267\n",
      "epoch= 20 \t time= 137.26012134552002 \t loss= 0.035663222074508664\n",
      "epoch= 25 \t time= 169.8927869796753 \t loss= 0.03106556922197342\n",
      "epoch= 30 \t time= 202.71270513534546 \t loss= 0.026114320792257787\n",
      "epoch= 35 \t time= 235.30182552337646 \t loss= 0.02300059374421835\n",
      "epoch= 40 \t time= 267.9455683231354 \t loss= 0.019582093693315983\n",
      "epoch= 45 \t time= 300.62061762809753 \t loss= 0.017927758749574422\n",
      "epoch= 50 \t time= 333.2841913700104 \t loss= 0.017654642388224603\n",
      "epoch= 55 \t time= 365.82870626449585 \t loss= 0.017357175033539535\n",
      "epoch= 60 \t time= 398.45350670814514 \t loss= 0.01671259293332696\n",
      "epoch= 65 \t time= 431.0202729701996 \t loss= 0.01666948936879635\n",
      "epoch= 70 \t time= 463.6414883136749 \t loss= 0.016080802138894797\n",
      "epoch= 75 \t time= 496.2992811203003 \t loss= 0.015823697112500666\n",
      "epoch= 80 \t time= 529.0868554115295 \t loss= 0.01496394531801343\n",
      "epoch= 85 \t time= 561.5439786911011 \t loss= 0.014687291830778122\n",
      "epoch= 90 \t time= 594.0393660068512 \t loss= 0.014439574237912893\n",
      "epoch= 95 \t time= 626.6636521816254 \t loss= 0.01437337500974536\n",
      "epoch= 100 \t time= 659.3423068523407 \t loss= 0.014372707344591618\n",
      "epoch= 105 \t time= 691.8490841388702 \t loss= 0.014137773662805558\n",
      "epoch= 110 \t time= 724.4123516082764 \t loss= 0.014193903878331185\n",
      "epoch= 115 \t time= 756.9749655723572 \t loss= 0.013881645817309617\n",
      "epoch= 120 \t time= 789.7106394767761 \t loss= 0.01378463676199317\n",
      "epoch= 125 \t time= 822.3538980484009 \t loss= 0.013576599415391683\n",
      "epoch= 130 \t time= 854.9070858955383 \t loss= 0.01393954038619995\n",
      "epoch= 135 \t time= 887.745623588562 \t loss= 0.013584692869335413\n",
      "epoch= 140 \t time= 920.4466338157654 \t loss= 0.013469253201037645\n",
      "epoch= 145 \t time= 953.1367764472961 \t loss= 0.013642050549387932\n",
      "epoch= 150 \t time= 985.9697182178497 \t loss= 0.013586126416921616\n",
      "epoch= 155 \t time= 1018.6406998634338 \t loss= 0.01304553410038352\n",
      "epoch= 160 \t time= 1051.3428437709808 \t loss= 0.01310803098604083\n",
      "epoch= 165 \t time= 1083.8914740085602 \t loss= 0.012926246151328086\n",
      "epoch= 170 \t time= 1116.5203168392181 \t loss= 0.013043793607503176\n",
      "epoch= 175 \t time= 1149.0856409072876 \t loss= 0.01269650859758258\n",
      "epoch= 180 \t time= 1181.5122773647308 \t loss= 0.012508572470396757\n",
      "epoch= 185 \t time= 1214.2401959896088 \t loss= 0.012568945661187172\n",
      "epoch= 190 \t time= 1247.0196933746338 \t loss= 0.012742655780166388\n",
      "epoch= 195 \t time= 1279.7002267837524 \t loss= 0.01254671225324273\n",
      "epoch= 200 \t time= 1312.3353221416473 \t loss= 0.012181714419275522\n",
      "epoch= 205 \t time= 1345.0059008598328 \t loss= 0.012664471063762903\n",
      "epoch= 210 \t time= 1377.6378996372223 \t loss= 0.012269900999963284\n",
      "epoch= 215 \t time= 1410.1518158912659 \t loss= 0.0122228535823524\n",
      "epoch= 220 \t time= 1442.7600061893463 \t loss= 0.01221175180748105\n",
      "epoch= 225 \t time= 1475.4402339458466 \t loss= 0.012027754727751017\n",
      "epoch= 230 \t time= 1508.1944756507874 \t loss= 0.011983813792467117\n",
      "epoch= 235 \t time= 1541.0369365215302 \t loss= 0.011767264492809772\n",
      "epoch= 240 \t time= 1573.673317193985 \t loss= 0.01140124000608921\n",
      "epoch= 245 \t time= 1606.342930316925 \t loss= 0.011761779114603996\n",
      "epoch= 250 \t time= 1638.9860019683838 \t loss= 0.011633057538419962\n",
      "epoch= 255 \t time= 1671.5456511974335 \t loss= 0.011769944205880165\n",
      "epoch= 260 \t time= 1704.1888699531555 \t loss= 0.011481184978038073\n",
      "epoch= 265 \t time= 1736.8449211120605 \t loss= 0.011469190828502179\n",
      "epoch= 270 \t time= 1769.3418128490448 \t loss= 0.011348672248423099\n",
      "epoch= 275 \t time= 1801.9037704467773 \t loss= 0.011360557377338409\n",
      "epoch= 280 \t time= 1834.3641357421875 \t loss= 0.011365670207887889\n",
      "epoch= 285 \t time= 1866.9715859889984 \t loss= 0.010916194263845682\n",
      "epoch= 290 \t time= 1899.7663395404816 \t loss= 0.011111879348754882\n",
      "epoch= 295 \t time= 1932.376914024353 \t loss= 0.011254231873899699\n",
      "epoch= 300 \t time= 1964.96484375 \t loss= 0.011279585845768452\n",
      "epoch= 305 \t time= 1997.5466220378876 \t loss= 0.011059646997600793\n",
      "epoch= 310 \t time= 2030.289965391159 \t loss= 0.010735450126230717\n",
      "epoch= 315 \t time= 2063.233985185623 \t loss= 0.010803062971681356\n",
      "epoch= 320 \t time= 2095.8924181461334 \t loss= 0.011015790402889252\n",
      "epoch= 325 \t time= 2128.5977396965027 \t loss= 0.010785449557006358\n",
      "epoch= 330 \t time= 2161.148372888565 \t loss= 0.010835939273238181\n",
      "epoch= 335 \t time= 2193.7102303504944 \t loss= 0.010682135950773955\n",
      "epoch= 340 \t time= 2226.477585554123 \t loss= 0.01068633545190096\n",
      "epoch= 345 \t time= 2259.1276621818542 \t loss= 0.010546113308519124\n",
      "epoch= 350 \t time= 2291.9713096618652 \t loss= 0.010762363988906145\n",
      "epoch= 355 \t time= 2324.711282014847 \t loss= 0.01051322601735592\n",
      "epoch= 360 \t time= 2357.508444547653 \t loss= 0.01046084962785244\n",
      "epoch= 365 \t time= 2390.23681974411 \t loss= 0.010723874643445016\n",
      "epoch= 370 \t time= 2422.8921275138855 \t loss= 0.010570288505405187\n",
      "epoch= 375 \t time= 2455.501906633377 \t loss= 0.010388351902365684\n",
      "epoch= 380 \t time= 2488.1306030750275 \t loss= 0.010430017858743668\n",
      "epoch= 385 \t time= 2520.724311351776 \t loss= 0.010595031641423702\n",
      "epoch= 390 \t time= 2553.325597047806 \t loss= 0.010463099665939809\n",
      "epoch= 395 \t time= 2585.9203000068665 \t loss= 0.01043558731675148\n",
      "epoch= 400 \t time= 2618.5581154823303 \t loss= 0.010247442461550236\n",
      "epoch= 405 \t time= 2651.454137802124 \t loss= 0.01012152986600995\n",
      "epoch= 410 \t time= 2684.1660690307617 \t loss= 0.01045923525467515\n",
      "epoch= 415 \t time= 2716.980365753174 \t loss= 0.010301589034497738\n",
      "epoch= 420 \t time= 2749.5263619422913 \t loss= 0.010192240402102471\n",
      "epoch= 425 \t time= 2782.159132003784 \t loss= 0.010305693186819554\n",
      "epoch= 430 \t time= 2814.7215032577515 \t loss= 0.010177957732230425\n",
      "epoch= 435 \t time= 2847.3763847351074 \t loss= 0.010370837077498436\n",
      "epoch= 440 \t time= 2879.858645915985 \t loss= 0.01020481511950493\n",
      "epoch= 445 \t time= 2912.70391869545 \t loss= 0.010094356667250394\n",
      "epoch= 450 \t time= 2945.2951679229736 \t loss= 0.01012725342065096\n",
      "epoch= 455 \t time= 2977.995668411255 \t loss= 0.010032339543104172\n",
      "epoch= 460 \t time= 3010.6255826950073 \t loss= 0.009855648390948773\n",
      "epoch= 465 \t time= 3043.1623315811157 \t loss= 0.01010293560102582\n",
      "epoch= 470 \t time= 3075.814719438553 \t loss= 0.010321492105722427\n",
      "epoch= 475 \t time= 3108.2928845882416 \t loss= 0.010039206612855196\n",
      "epoch= 480 \t time= 3140.9744226932526 \t loss= 0.009859465882182122\n",
      "epoch= 485 \t time= 3173.5289812088013 \t loss= 0.009937772490084172\n",
      "epoch= 490 \t time= 3206.277711868286 \t loss= 0.010030854437500238\n",
      "epoch= 495 \t time= 3238.938060283661 \t loss= 0.010054964795708657\n",
      "epoch= 500 \t time= 3271.467235803604 \t loss= 0.00990309963002801\n",
      "epoch= 505 \t time= 3303.8622665405273 \t loss= 0.009799304232001305\n",
      "epoch= 510 \t time= 3336.329271554947 \t loss= 0.00978906786069274\n",
      "epoch= 515 \t time= 3368.8534712791443 \t loss= 0.009719275012612343\n",
      "epoch= 520 \t time= 3401.435688018799 \t loss= 0.009796496517956256\n",
      "epoch= 525 \t time= 3434.1521627902985 \t loss= 0.009835889302194119\n",
      "epoch= 530 \t time= 3466.7657372951508 \t loss= 0.009811745434999465\n",
      "epoch= 535 \t time= 3499.2202966213226 \t loss= 0.009786469731479883\n",
      "epoch= 540 \t time= 3531.9041855335236 \t loss= 0.00955083318054676\n",
      "epoch= 545 \t time= 3564.566129922867 \t loss= 0.009769510198384523\n",
      "epoch= 550 \t time= 3597.1455376148224 \t loss= 0.009703644718974828\n",
      "epoch= 555 \t time= 3629.866127729416 \t loss= 0.009773238264024257\n",
      "epoch= 560 \t time= 3662.4279181957245 \t loss= 0.009720238782465458\n",
      "epoch= 565 \t time= 3694.897875070572 \t loss= 0.009676806181669235\n",
      "epoch= 570 \t time= 3727.533383131027 \t loss= 0.009569382816553116\n",
      "epoch= 575 \t time= 3760.0749385356903 \t loss= 0.009552317578345538\n",
      "epoch= 580 \t time= 3792.807667016983 \t loss= 0.009595263507217169\n",
      "epoch= 585 \t time= 3825.65118932724 \t loss= 0.009592252112925052\n",
      "epoch= 590 \t time= 3858.4046988487244 \t loss= 0.009505185224115848\n",
      "epoch= 595 \t time= 3891.1513345241547 \t loss= 0.009658954292535781\n",
      "epoch= 600 \t time= 3923.9100816249847 \t loss= 0.009544575829058885\n",
      "epoch= 605 \t time= 3956.667881965637 \t loss= 0.009678452368825674\n",
      "epoch= 610 \t time= 3989.462648630142 \t loss= 0.009524777699261903\n",
      "epoch= 615 \t time= 4022.1962890625 \t loss= 0.009543926864862442\n",
      "epoch= 620 \t time= 4054.9987189769745 \t loss= 0.00946141866967082\n",
      "epoch= 625 \t time= 4087.8864057064056 \t loss= 0.009494976382702589\n",
      "epoch= 630 \t time= 4120.869347572327 \t loss= 0.009335038010030985\n",
      "epoch= 635 \t time= 4153.44252872467 \t loss= 0.009350577592849732\n",
      "epoch= 640 \t time= 4185.159787416458 \t loss= 0.009389049764722586\n",
      "epoch= 645 \t time= 4216.491863965988 \t loss= 0.009405243434011936\n",
      "epoch= 650 \t time= 4247.856432199478 \t loss= 0.009411345273256301\n",
      "epoch= 655 \t time= 4279.09813117981 \t loss= 0.009463253449648618\n",
      "epoch= 660 \t time= 4310.479863643646 \t loss= 0.00935980686917901\n",
      "epoch= 665 \t time= 4341.744378089905 \t loss= 0.009301115702837705\n",
      "epoch= 670 \t time= 4372.957396268845 \t loss= 0.009220732413232326\n",
      "epoch= 675 \t time= 4404.197231769562 \t loss= 0.009311016593128442\n",
      "epoch= 680 \t time= 4435.464071273804 \t loss= 0.009296254441142082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.IVEModelfit at 0x7f200c7ab820>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we load the data and start the training\n",
    "# baseline experiment: model01\n",
    "# input: x,y,object, output:u,v,p. No FV attributes.\n",
    "\n",
    "train_data = torch.load('train.pickle')\n",
    "val_data = torch.load('val.pickle')\n",
    "\n",
    "path = 'IVE_Models/model01_00/'\n",
    "trained = IVEModelfit(input_size = 3,\n",
    "                      input_edge_feat = 3,\n",
    "                      edge_feature_dim=[4,8,16,32,64,64,32,16],\n",
    "                      num_filters=[8,16,32,64,64,32,16,8],\n",
    "                      output_size = 3,\n",
    "                      node_attr_num=0, edge_attr_num=0, FV_hidden_size=0,\n",
    "                      device='cuda:0')\n",
    "trained.fit(path, train_data, val_data, max_epoch=1000, bs=64, lr=0.002, weight_decay=0.002, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ntuzfs/jessica/anaconda3/envs/cu113py39/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 \t time= 6.798266410827637 \t loss= 0.12525332629680633\n",
      "epoch= 5 \t time= 41.412795066833496 \t loss= 0.0595178634673357\n",
      "epoch= 10 \t time= 75.85290288925171 \t loss= 0.04240341477096081\n",
      "epoch= 15 \t time= 110.55145764350891 \t loss= 0.027491466663777827\n",
      "epoch= 20 \t time= 145.94313669204712 \t loss= 0.022698229737579824\n",
      "epoch= 25 \t time= 180.5417604446411 \t loss= 0.021078452430665494\n",
      "epoch= 30 \t time= 214.50816679000854 \t loss= 0.018639970235526562\n",
      "epoch= 35 \t time= 248.8865180015564 \t loss= 0.016500208023935557\n",
      "epoch= 40 \t time= 283.21240186691284 \t loss= 0.014299478940665722\n",
      "epoch= 45 \t time= 318.8955397605896 \t loss= 0.013248862009495497\n",
      "epoch= 50 \t time= 353.99534249305725 \t loss= 0.013119911532849074\n",
      "epoch= 55 \t time= 388.9277377128601 \t loss= 0.012882695086300373\n",
      "epoch= 60 \t time= 422.9955401420593 \t loss= 0.012236639000475407\n",
      "epoch= 65 \t time= 458.3000657558441 \t loss= 0.012375181633979082\n",
      "epoch= 70 \t time= 492.57055592536926 \t loss= 0.01232894668355584\n",
      "epoch= 75 \t time= 526.1876263618469 \t loss= 0.011648783423006535\n",
      "epoch= 80 \t time= 559.6470513343811 \t loss= 0.011251223962754011\n",
      "epoch= 85 \t time= 594.2220854759216 \t loss= 0.010685386639088391\n",
      "epoch= 90 \t time= 627.9327149391174 \t loss= 0.010760736092925072\n",
      "epoch= 95 \t time= 661.9594140052795 \t loss= 0.010611380767077207\n",
      "epoch= 100 \t time= 695.7521376609802 \t loss= 0.010426242407411336\n",
      "epoch= 105 \t time= 729.4976623058319 \t loss= 0.010444531571120024\n",
      "epoch= 110 \t time= 763.7496950626373 \t loss= 0.010885803867131472\n",
      "epoch= 115 \t time= 797.7687337398529 \t loss= 0.010552990138530732\n",
      "epoch= 120 \t time= 832.0858750343323 \t loss= 0.009905978310853243\n",
      "epoch= 125 \t time= 866.0514802932739 \t loss= 0.01213480044156313\n",
      "epoch= 130 \t time= 899.7831494808197 \t loss= 0.011489243023097515\n",
      "epoch= 135 \t time= 934.6259400844574 \t loss= 0.011151790767908096\n",
      "epoch= 140 \t time= 968.6419930458069 \t loss= 0.011274624709039926\n",
      "epoch= 145 \t time= 1004.0360152721405 \t loss= 0.010426493715494872\n",
      "epoch= 150 \t time= 1037.906163930893 \t loss= 0.010238815695047379\n",
      "epoch= 155 \t time= 1072.5889236927032 \t loss= 0.010234934855252504\n",
      "epoch= 160 \t time= 1107.1187739372253 \t loss= 0.010264732036739587\n",
      "epoch= 165 \t time= 1141.0215094089508 \t loss= 0.009298934880644084\n",
      "epoch= 170 \t time= 1175.2567081451416 \t loss= 0.00895715283229947\n"
     ]
    }
   ],
   "source": [
    "# now we load the data and start the training\n",
    "# SAF and dSDF experiment: model02\n",
    "# input: x,y,SAF,dSDF, output:u,v,p. No FV attributes.\n",
    "\n",
    "train_data = torch.load('train2.pickle')\n",
    "val_data = torch.load('val2.pickle')\n",
    "\n",
    "path = 'IVE_Models/model02_TEST00/'\n",
    "trained = IVEModelfit(input_size = 12,\n",
    "                      input_edge_feat = 12,\n",
    "                      edge_feature_dim=[4,8,16,32,64,64,32,16],\n",
    "                      num_filters=[8,16,32,64,64,32,16,8],\n",
    "                      output_size = 3,\n",
    "                      node_attr_num=0, edge_attr_num=0, FV_hidden_size=0,\n",
    "                      device='cuda:0')\n",
    "trained.fit(path, train_data, val_data, max_epoch=1000, bs=64, lr=0.002, weight_decay=0.002, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test and print the test MAE loss\n",
    "\n",
    "def testIVE(model, dataset, device='cuda:1'):\n",
    "    model = model.to(device); model.eval()\n",
    "    criterion = nn.L1Loss().to(device)\n",
    "    testLoader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    running_loss = 0; num_batches = 0\n",
    "    for batch_list in testLoader:\n",
    "        batch_list = batch_list.to(device)\n",
    "        outputs, GTy = model(batch_list)\n",
    "        loss = criterion(outputs, GTy)\n",
    "        # add the loss of this batch to the running loss\n",
    "        running_loss += loss.detach().item(); num_batches+=1\n",
    "\n",
    "    # compute stats for the full training set\n",
    "    total_loss = running_loss/num_batches\n",
    "    torch.set_grad_enabled(True)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jessica/anaconda3/envs/airfrans_env/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:  0.011823220876976848\n",
      "number of parmeters:  217853\n"
     ]
    }
   ],
   "source": [
    "test_data = torch.load('test.pickle')\n",
    "best_model = torch.load('IVE_Models/model01/IVEModel_checkpoint_409.txt')\n",
    "\n",
    "test_loss = testIVE(best_model, test_data, device='cuda:1')\n",
    "print('test_loss: ',test_loss)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, best_model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('number of parmeters: ',params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ntuzfs/jessica/anaconda3/envs/cu113py39/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:  0.00660703303758055\n",
      "number of parmeters:  222461\n"
     ]
    }
   ],
   "source": [
    "test_data = torch.load('test2.pickle')\n",
    "best_model = torch.load('IVE_Models/model02/IVEModel_checkpoint_506.txt')\n",
    "\n",
    "test_loss = testIVE(best_model, test_data, device='cuda:1')\n",
    "print('test_loss: ',test_loss)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, best_model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('number of parmeters: ',params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**Model3**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIMPLEST ONE: just concatenate the edge attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the network as described in (https://github.com/cfl-minds/gnn_laminar_flow)\n",
    "# but using pyTorch\n",
    "\n",
    "class swish(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "###################################\n",
    "## InvariantEdgeFVConv CLASS DEF ##\n",
    "###################################\n",
    "#@title InvariantEdgeFVConv codes, with node_attr_num and edge_attr_num for FV\n",
    "class InvariantEdgeFVConv(nng.conv.MessagePassing): #InvariantEdgeConv(nng.conv.GCNConv):\n",
    "    '''Convolutions class as described in paper, built on GCNConv, \n",
    "    with SGCN and FVnew adaptations'''\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        #aggr: Optional[Union[str, List[str], Aggregation]] = 'add',\n",
    "\n",
    "        old_mlp_ief: int = 0, #paper: previous edge feature dimension\n",
    "        mlp_hs: int = 128, #paper: two MLPs with hidden size 128 used\n",
    "        mlp_ief: int = 1, #paper: one MLP with intermediate edge feature dimension fe\n",
    "        \n",
    "        node_attr_num: int = 1, #FVnew: number of persistent node_attr\n",
    "        edge_attr_num: int = 6, #FVnew: number of edge_attr + rel_node_attr\n",
    "        # hidden_size: int = 0, #sGCN: convolution internal hidden size\n",
    "        dropout: float = 0, #sGCN: dropout\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels + node_attr_num\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        #paper####\n",
    "        # self.mlp_message = nng.MLP([in_channels*2+old_mlp_ief, mlp_hs, mlp_ief],act='swish', bias=True)\n",
    "        # self.mlp_update = nng.MLP([mlp_ief+in_channels, mlp_hs, out_channels],act='swish', bias=True)\n",
    "        self.mlp_message = torchvision.ops.MLP(self.in_channels*2+old_mlp_ief+edge_attr_num, [mlp_hs, mlp_ief], \\\n",
    "                                               activation_layer=swish, bias=True)\n",
    "        self.mlp_update = torchvision.ops.MLP(mlp_ief+self.in_channels, [mlp_hs, out_channels], \\\n",
    "                                              activation_layer=swish, bias=True)\n",
    "        self.new_edge_features = None #torch.tensor([0.])\n",
    "\n",
    "        #FVnew or sGCN####\n",
    "        # self.lin_in = torch.nn.Linear(edge_attr_num, hidden_size * in_channels)\n",
    "        # self.lin_in = torch.nn.Linear(edge_attr_num, mlp_ief)\n",
    "        # self.lin_out = torch.nn.Linear(hidden_size * in_channels, out_channels)\n",
    "        # self.dropout = dropout ####\n",
    "\n",
    "    #def forward(self, x: Tensor, edge_index: Adj, edge_weight: OptTensor = None) -> Tensor:\n",
    "    def forward(self, x, edge_index, edge_feat=None, edge_attr=None, node_attr=None):\n",
    "\n",
    "        if (node_attr is not None): #for FVnew\n",
    "            x = torch.cat((x,node_attr),dim=1) #persistent node_attr.\n",
    "\n",
    "        # if edge_feat is None: #for paper: previous edge feat added if existent\n",
    "        #     edge_feat = torch.zeros((edge_index.size(1),1))\n",
    "        out = self.propagate(x=x, edge_index=edge_index, edge_feat=edge_feat, edge_attr=edge_attr) #for FVnew\n",
    "\n",
    "        return out, self.new_edge_features\n",
    "\n",
    "    #def message(self, x_j: Tensor, edge_weight: OptTensor) -> Tensor:\n",
    "    #   return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
    "    def message(self, x_j, x_i, edge_feat, edge_attr=None):\n",
    "        \"\"\"\n",
    "        x_j [num_edges, label_dim]\n",
    "        x_i [num_edges, label_dim]\n",
    "        edge_attr [num_edges, #attr] or none ##ADDED\n",
    "        \"\"\"\n",
    "        symmetric = (x_j + x_i)/2 #paper: symmetric node features\n",
    "        asymmetric = abs(x_j - x_i)/2 #instead of raw features x_j and x_i\n",
    "        if edge_feat is not None:\n",
    "            if edge_attr is not None:\n",
    "                new_edge_feat = torch.cat((symmetric,asymmetric,edge_feat,edge_attr),dim=1)\n",
    "            else:\n",
    "                new_edge_feat = torch.cat((symmetric,asymmetric,edge_feat),dim=1)\n",
    "        else:\n",
    "            new_edge_feat = torch.cat((symmetric,asymmetric),dim=1)\n",
    "        message = self.mlp_message(new_edge_feat)\n",
    "        \n",
    "        # message = message * F.sigmoid(message) #MLP swish activation if act was None\n",
    "        self.new_edge_features = message\n",
    "\n",
    "        ##for FVnew ####\n",
    "        # if edge_attr is not None: \n",
    "        #   scaling = F.relu(self.lin_in(edge_attr))  # [n_edges, hidden_size * in_channels]\n",
    "        # else:\n",
    "        #   scaling = torch.ones(x_j.size()).unsqueeze(-1).to(x_j.device)\n",
    "        # n_edges = x_j.size(0)\n",
    "        # # [n_edges, in_channels, ...] * [n_edges, in_channels, 1]\n",
    "        # # result = scaling.reshape(n_edges, self.in_channels, -1) * message.unsqueeze(-1)\n",
    "        # result = scaling.reshape(n_edges, -1) * message\n",
    "        ####\n",
    "\n",
    "        return message #result.view(n_edges, -1)\n",
    "\n",
    "    #def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "    #    return spmm(adj_t, x, reduce=self.aggr)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        \"\"\"\n",
    "        x_j [num_nodes, label_dim, 1]\n",
    "        aggr_out [num_nodes, label_dim, out_channels]\n",
    "        \"\"\"\n",
    "        aggr_out = torch.cat((x,aggr_out),dim=1) #paper\n",
    "        aggr_out = self.mlp_update(aggr_out)\n",
    "        # aggr_out = aggr_out * F.sigmoid(aggr_out) #MLP swish activation if act was None\n",
    "\n",
    "        ##for sGCN ####\n",
    "        # aggr_out = self.lin_out(aggr_out)  #[num_nodes, label_dim, out_features]\n",
    "        # aggr_out = torch.tanh(aggr_out); #aggr_out = F.relu(aggr_out)\n",
    "        # aggr_out = F.dropout(aggr_out, p=self.dropout, training=self.training)\n",
    "        ####\n",
    "\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jessica/anaconda3/envs/lim_wp5/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 \t time= 15.893697738647461 \t loss= 0.1820575028657913\n",
      "epoch= 5 \t time= 69.43811535835266 \t loss= 0.07708506971597671\n",
      "epoch= 10 \t time= 118.29100823402405 \t loss= 0.0685136365890503\n",
      "epoch= 15 \t time= 167.4692735671997 \t loss= 0.061980309933423995\n",
      "epoch= 20 \t time= 216.03236889839172 \t loss= 0.05479741886258125\n",
      "epoch= 25 \t time= 261.13044691085815 \t loss= 0.0505585926771164\n",
      "epoch= 30 \t time= 306.0433759689331 \t loss= 0.047943304926157\n",
      "epoch= 35 \t time= 351.378751039505 \t loss= 0.03491306498646736\n",
      "epoch= 40 \t time= 395.67210483551025 \t loss= 0.030647451430559157\n",
      "epoch= 45 \t time= 441.6814298629761 \t loss= 0.02928360678255558\n",
      "epoch= 50 \t time= 487.191609621048 \t loss= 0.02701968662440777\n",
      "epoch= 55 \t time= 531.8305928707123 \t loss= 0.02537402592599392\n",
      "epoch= 60 \t time= 578.0391874313354 \t loss= 0.022810547053813933\n",
      "epoch= 65 \t time= 624.734338760376 \t loss= 0.022880838662385942\n",
      "epoch= 70 \t time= 669.6569032669067 \t loss= 0.020208725035190583\n",
      "epoch= 75 \t time= 715.3023483753204 \t loss= 0.02096676416695118\n",
      "epoch= 80 \t time= 760.5939826965332 \t loss= 0.017715211808681488\n",
      "epoch= 85 \t time= 807.207533121109 \t loss= 0.016539102345705034\n",
      "epoch= 90 \t time= 852.9297921657562 \t loss= 0.01632290404289961\n",
      "epoch= 95 \t time= 898.291656255722 \t loss= 0.015292289853096008\n",
      "epoch= 100 \t time= 942.8807542324066 \t loss= 0.01555361669510603\n",
      "epoch= 105 \t time= 987.4762117862701 \t loss= 0.014987207427620887\n",
      "epoch= 110 \t time= 1032.216802597046 \t loss= 0.015227656960487366\n",
      "epoch= 115 \t time= 1077.5467867851257 \t loss= 0.013534570001065732\n",
      "epoch= 120 \t time= 1122.8378412723541 \t loss= 0.013493642844259739\n",
      "epoch= 125 \t time= 1167.1593849658966 \t loss= 0.013363750651478767\n",
      "epoch= 130 \t time= 1212.684913635254 \t loss= 0.012723770178854465\n",
      "epoch= 135 \t time= 1257.22877907753 \t loss= 0.012966231629252433\n",
      "epoch= 140 \t time= 1438.6334338188171 \t loss= 0.013410878628492355\n",
      "epoch= 145 \t time= 1484.263192653656 \t loss= 0.012788988836109638\n",
      "epoch= 150 \t time= 1529.1601388454437 \t loss= 0.0124624365568161\n",
      "epoch= 155 \t time= 1574.251267194748 \t loss= 0.011853782050311566\n",
      "epoch= 160 \t time= 1618.8043961524963 \t loss= 0.011510972380638123\n",
      "epoch= 165 \t time= 1663.149228811264 \t loss= 0.011007147692143917\n",
      "epoch= 170 \t time= 1706.9371848106384 \t loss= 0.011308841034770012\n",
      "epoch= 175 \t time= 1750.3368701934814 \t loss= 0.011035325974225997\n",
      "epoch= 180 \t time= 1793.7819321155548 \t loss= 0.010840157531201839\n",
      "epoch= 185 \t time= 1837.0736391544342 \t loss= 0.011006619483232498\n",
      "epoch= 190 \t time= 1880.6649837493896 \t loss= 0.010997779704630374\n",
      "epoch= 195 \t time= 1923.0058662891388 \t loss= 0.010962651669979095\n",
      "epoch= 200 \t time= 1966.0325894355774 \t loss= 0.011134755089879036\n",
      "epoch= 205 \t time= 2008.8151111602783 \t loss= 0.010928977467119693\n",
      "epoch= 210 \t time= 2051.755397081375 \t loss= 0.01094091597944498\n",
      "epoch= 215 \t time= 2094.711878299713 \t loss= 0.011074370667338372\n",
      "epoch= 220 \t time= 2137.8557527065277 \t loss= 0.010620140433311463\n",
      "epoch= 225 \t time= 2180.717223882675 \t loss= 0.01235190600156784\n",
      "epoch= 230 \t time= 2223.416898727417 \t loss= 0.01222952339798212\n",
      "epoch= 235 \t time= 2266.8030393123627 \t loss= 0.01175916776061058\n",
      "epoch= 240 \t time= 2311.9381127357483 \t loss= 0.01135817777365446\n",
      "epoch= 245 \t time= 2355.74174284935 \t loss= 0.010586484782397747\n",
      "epoch= 250 \t time= 2399.4278848171234 \t loss= 0.01297708485275507\n",
      "epoch= 255 \t time= 2441.9077022075653 \t loss= 0.01113089695572853\n",
      "epoch= 260 \t time= 2484.8701255321503 \t loss= 0.010736477598547935\n",
      "epoch= 265 \t time= 2527.886642932892 \t loss= 0.010790997594594955\n",
      "epoch= 270 \t time= 2570.335534095764 \t loss= 0.010666770786046982\n",
      "epoch= 275 \t time= 2613.293719291687 \t loss= 0.011376165822148322\n",
      "epoch= 280 \t time= 2656.4646339416504 \t loss= 0.01051996961236\n",
      "epoch= 285 \t time= 2699.733792066574 \t loss= 0.010345184244215488\n",
      "epoch= 290 \t time= 2742.942425966263 \t loss= 0.010712144635617734\n",
      "epoch= 295 \t time= 2786.244923353195 \t loss= 0.010693051852285862\n",
      "epoch= 300 \t time= 2829.1392471790314 \t loss= 0.010312595404684544\n",
      "epoch= 305 \t time= 2872.559339284897 \t loss= 0.009527137540280818\n",
      "epoch= 310 \t time= 2915.775356054306 \t loss= 0.00942438330501318\n",
      "epoch= 315 \t time= 2960.873393535614 \t loss= 0.00963157955557108\n",
      "epoch= 320 \t time= 3006.767317533493 \t loss= 0.010498226992785931\n",
      "epoch= 325 \t time= 3052.3542149066925 \t loss= 0.010192759782075882\n",
      "epoch= 330 \t time= 3097.6853840351105 \t loss= 0.010008304379880428\n",
      "epoch= 335 \t time= 3143.585313796997 \t loss= 0.010348188802599906\n",
      "epoch= 340 \t time= 3188.7925429344177 \t loss= 0.010381698831915856\n",
      "epoch= 345 \t time= 3234.3618066310883 \t loss= 0.009777763485908508\n",
      "epoch= 350 \t time= 3279.6759283542633 \t loss= 0.009742167927324772\n",
      "epoch= 355 \t time= 3325.248386859894 \t loss= 0.010479229614138602\n",
      "epoch= 360 \t time= 3369.965888261795 \t loss= 0.00964332427829504\n",
      "epoch= 365 \t time= 3414.585304737091 \t loss= 0.009595651924610139\n",
      "epoch= 370 \t time= 3460.619416475296 \t loss= 0.01050214033573866\n",
      "epoch= 375 \t time= 3505.8054625988007 \t loss= 0.0108415262773633\n",
      "epoch= 380 \t time= 3550.766156435013 \t loss= 0.01017437294125557\n",
      "epoch= 385 \t time= 3595.5713455677032 \t loss= 0.010028246492147445\n",
      "epoch= 390 \t time= 3640.8063514232635 \t loss= 0.009893775694072246\n",
      "epoch= 395 \t time= 3686.2397921085358 \t loss= 0.009661085158586501\n",
      "epoch= 400 \t time= 3731.798909187317 \t loss= 0.009102379269897938\n",
      "epoch= 405 \t time= 3777.462153196335 \t loss= 0.00892242405563593\n",
      "epoch= 410 \t time= 3822.9873521327972 \t loss= 0.008907078057527542\n",
      "epoch= 415 \t time= 3867.4261000156403 \t loss= 0.008943400494754315\n",
      "epoch= 420 \t time= 3912.5026795864105 \t loss= 0.008914581015706063\n",
      "epoch= 425 \t time= 3958.3142516613007 \t loss= 0.008790000900626182\n",
      "epoch= 430 \t time= 4003.7099528312683 \t loss= 0.008992271572351456\n",
      "epoch= 435 \t time= 4048.991681098938 \t loss= 0.008583114072680474\n",
      "epoch= 440 \t time= 4094.08518075943 \t loss= 0.008921233825385571\n",
      "epoch= 445 \t time= 4139.1799528598785 \t loss= 0.00913568925112486\n",
      "epoch= 450 \t time= 4184.205950021744 \t loss= 0.008821003176271915\n",
      "epoch= 455 \t time= 4229.429967164993 \t loss= 0.008815970495343209\n",
      "epoch= 460 \t time= 4274.621799707413 \t loss= 0.008985411077737808\n",
      "epoch= 465 \t time= 4319.583434104919 \t loss= 0.009222062490880489\n",
      "epoch= 470 \t time= 4364.976938962936 \t loss= 0.00910691063851118\n",
      "epoch= 475 \t time= 4409.915277004242 \t loss= 0.008825680315494537\n",
      "epoch= 480 \t time= 4454.394877910614 \t loss= 0.00903541162610054\n",
      "epoch= 485 \t time= 4499.109982967377 \t loss= 0.00912233378738165\n",
      "epoch= 490 \t time= 4544.404118537903 \t loss= 0.008930772095918655\n",
      "epoch= 495 \t time= 4589.440781354904 \t loss= 0.008682604655623436\n",
      "epoch= 500 \t time= 4633.762697219849 \t loss= 0.009952830485999584\n",
      "epoch= 505 \t time= 4678.610152721405 \t loss= 0.009599542804062366\n",
      "epoch= 510 \t time= 4723.931981086731 \t loss= 0.009048716947436333\n",
      "epoch= 515 \t time= 4768.629833698273 \t loss= 0.010059255845844746\n",
      "epoch= 520 \t time= 4813.197099685669 \t loss= 0.009122201725840568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.IVEFVModelfit at 0x7fc71ebb7f40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we load the data and start the training\n",
    "# FV experiment: model02\n",
    "# input: x,y,SAF,dSDF, output:u,v,p. WITH FV attributes.\n",
    "\n",
    "train_data = torch.load('train3.pickle')\n",
    "val_data = torch.load('val3.pickle')\n",
    "\n",
    "path = 'IVE_Models/model03c_00/'\n",
    "trained = IVEFVModelfit(input_size = 12,\n",
    "                      input_edge_feat = 12,\n",
    "                      edge_feature_dim=[4,8,16,32,64,64,32,16],\n",
    "                      num_filters=[8,16,32,64,64,32,16,8],\n",
    "                      output_size = 3,\n",
    "                      node_attr_num=1,\n",
    "                      edge_attr_num=6,\n",
    "                      device='cuda:1')\n",
    "trained.fit(path, train_data, val_data, max_epoch=1000, bs=64, lr=0.002, weight_decay=0.002, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jessica/anaconda3/envs/lim_wp5/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:  0.008490977995097636\n",
      "number of parmeters:  231677\n"
     ]
    }
   ],
   "source": [
    "test_data = torch.load('test3.pickle')\n",
    "best_model = torch.load('IVE_Models/model03c_00/IVEModel_checkpoint_460.txt')\n",
    "\n",
    "test_loss = testIVE(best_model, test_data, device='cuda:1')\n",
    "print('test_loss: ',test_loss)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, best_model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('number of parmeters: ',params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
